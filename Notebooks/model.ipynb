{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "from keras.layers import Dense,GlobalAveragePooling2D\n",
    "from keras.layers import Dropout\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import img_to_array\n",
    "\n",
    "# Pretrained Models\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications import MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetuning_model():\n",
    "    base_model=VGG16(weights='imagenet',include_top=False)\n",
    "\n",
    "    x=base_model.output\n",
    "    x=GlobalAveragePooling2D()(x)\n",
    "    x=Dropout(0.25)(x)\n",
    "    x=Dense(1024,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n",
    "    x=Dense(1024,activation='relu')(x) #dense layer 2\n",
    "    x=Dense(512,activation='relu')(x) #dense layer 3\n",
    "    preds=Dense(2,activation='softmax')(x) #final layer with softmax activation\n",
    "\n",
    "    model=Model(inputs=base_model.input,outputs=preds)\n",
    "\n",
    "    for layer in model.layers[:20]:\n",
    "        layer.trainable=False\n",
    "    for layer in model.layers[20:]:\n",
    "        layer.trainable=True\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlotLossAcc():\n",
    "    \n",
    "    def __init__(self, history):\n",
    "        self.history = history\n",
    "        \n",
    "    def plot_loss_acc(self):\n",
    "        # Plot training & validation accuracy values\n",
    "        plt.plot(self.history.history['acc'])\n",
    "        plt.plot(self.history.history['val_acc'])\n",
    "        plt.title('Model accuracy')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend(['Train', 'Test'], loc='upper left')\n",
    "        plt.savefig('accuracy-{}.png'.format(self.history.history['val_acc']))\n",
    "        plt.show()\n",
    "\n",
    "        # Plot training & validation loss values\n",
    "        plt.plot(self.history.history['loss'])\n",
    "        plt.plot(self.history.history['val_loss'])\n",
    "        plt.title('Model loss')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend(['Train', 'Test'], loc='upper left')\n",
    "        plt.savefig('loss-{}.png'.format(self.history.history['val_loss']))\n",
    "        plt.show()\n",
    "    \n",
    "    def save_history(self):\n",
    "        json.dump(self.history.history, open('../history/history.json', 'w'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator():\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input) #included in our dependencies\n",
    "        self.train_generator = None\n",
    "        self.valid_generator = None\n",
    "        self.step_size_train = None\n",
    "        self.step_size_valid = None\n",
    "        \n",
    "    def train_test_generator(self, train_path='../data/training-data', test_path='../data/testing-data'):\n",
    "        \n",
    "        self.train_generator = self.train_datagen.flow_from_directory(train_path,\n",
    "                                                         target_size=(64,64),\n",
    "                                                         color_mode='rgb',\n",
    "                                                         batch_size=32,\n",
    "                                                         class_mode='categorical',\n",
    "                                                         shuffle=True)\n",
    "        self.valid_generator = self.train_datagen.flow_from_directory(test_path,\n",
    "                                                          target_size = (64,64),\n",
    "                                                          color_mode='rgb',\n",
    "                                                          batch_size=12,\n",
    "                                                          class_mode='categorical',\n",
    "                                                          shuffle=False)\n",
    "        \n",
    "        self.step_size_train = self.train_generator.n//self.train_generator.batch_size\n",
    "        self.step_size_valid = self.valid_generator.n//self.valid_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(model, epochs, lr):\n",
    "    print(\"epochs: {}, learning rate: {}\".format(epochs, lr))\n",
    "    print()\n",
    "    print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = DataGenerator()\n",
    "d.train_test_generator()\n",
    "\n",
    "epochs = 1\n",
    "lr = 1e-4\n",
    "\n",
    "Adam = keras.optimizers.Adam(lr=lr)\n",
    "\n",
    "model = finetuning_model()\n",
    "print_stats(model, epochs, lr)\n",
    "model.compile(optimizer=Adam,loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "history = model.fit_generator(generator=d.train_generator,\n",
    "                              steps_per_epoch=d.step_size_train,\n",
    "                              validation_data=d.valid_generator,\n",
    "                              validation_steps=d.step_size_valid,\n",
    "                              epochs=epochs)\n",
    "\n",
    "model.save('VGG16-{}-{}-adam.h5'.format(epochs, lr,))\n",
    "h = PlotLossAcc(history)\n",
    "h.plot_loss_acc()\n",
    "h.save_history()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
