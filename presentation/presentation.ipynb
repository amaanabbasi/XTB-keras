{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN In Image Classification\n",
    "\n",
    "CNNs are biologically-inspired models inspired by research by D. H. Hubel and T. N. Wiesel. They proposed an explanation for the way in which mammals visually perceive the world around them using a layered architecture of neurons in the brain, and this in turn inspired engineers to attempt to develop similar pattern recognition mechanisms in computer vision.\n",
    "\n",
    "alt text\n",
    "\n",
    "In their hypothesis, within the __visual cortex__, complex functional responses generated by \"complex cells\" are constructed from more simplistic responses from \"simple cells'.\n",
    "\n",
    "For instances, simple cells would respond to oriented edges etc, while complex cells will also respond to oriented edges but with a degree of spatial invariance.\n",
    "\n",
    "Receptive fields exist for cells, where a cell responds to a summation of inputs from other local cells.\n",
    "\n",
    "The architecture of deep convolutional neural networks was inspired by the ideas mentioned above\n",
    "\n",
    "local connections\n",
    "layering\n",
    "spatial invariance (shifting the input signal results in an equally shifted output signal. , most of us are able to recognize specific faces under a variety of conditions because we learn abstraction These abstractions are thus invariant to size, contrast, rotation, orientation\n",
    "However, it remains to be seen if these computational mechanisms of convolutional neural networks are similar to the computation mechanisms occurring in the primate visual system\n",
    "\n",
    "convolution operation\n",
    "shared weights\n",
    "pooling/subsampling\n",
    "\n",
    "\n",
    "## How Computer Sees An Image\n",
    "\n",
    "For a computer an image is an array of numbers. \n",
    "![](./img/img-matrix.png)\n",
    "\n",
    "\n",
    "##  How it works \n",
    "\n",
    "\n",
    "![](./img/Howitworks.jpeg)\n",
    "![](./img/cnn.jpeg)\n",
    "\n",
    "\n",
    "##  Prepare DataSet of images\n",
    "   \n",
    "A neural network learns from examples of things that you want it to make predictions on.\n",
    "\n",
    "##  Convolution\n",
    "\n",
    "![](./img/convolution.gif)\n",
    "![](./img/cnn.png)\n",
    "\n",
    "A convolution is an orderly procedure where two sources of information are intertwined.\n",
    "\n",
    "A kernel (also called a filter) is a smaller-sized matrix in comparison to the input dimensions of the image, that consists of real valued entries.\n",
    "\n",
    "Kernels are then convolved with the input volume to obtain so-called ‘activation maps’ (also called feature maps).\n",
    "\n",
    "Activation maps indicate ‘activated’ regions, i.e. regions where features specific to the kernel have been detected in the input.\n",
    "\n",
    "The real values of the kernel matrix change with each learning iteration over the training set, indicating that the network is learning to identify which regions are of significance for extracting features from the data.\n",
    "\n",
    "We compute the dot product between the kernel and the input matrix. -The convolved value obtained by summing the resultant terms from the dot product forms a single entry in the activation matrix.\n",
    "\n",
    "The patch selection is then slided (towards the right, or downwards when the boundary of the matrix is reached) by a certain amount called the ‘stride’ value, and the process is repeated till the entire input image has been processed. - The process is carried out for all colour channels.\n",
    "\n",
    "instead of connecting each neuron to all possible pixels, we specify a 2 dimensional region called the ‘receptive field[14]’ (say of size 5×5 units) extending to the entire depth of the input (5x5x3 for a 3 colour channel input), within which the encompassed pixels are fully connected to the neural network’s input layer. It’s over these small regions that the network layer cross-sections (each consisting of several neurons (called ‘depth columns’)) operate and produce the activation map. (reduces computational complexity)\n",
    "\n",
    "### Feature\n",
    "\n",
    "![](./img/img-feature.png)\n",
    "![](./img/cnn2.jpeg)\n",
    "\n",
    "Feature matrix or weight matrix are randomly initialized at first but later our tuned. \n",
    "\n",
    "## So how do we learn the magic numbers?\n",
    "\n",
    "We can learn features and weight values through backpropagation\n",
    "\n",
    "![](./img/backpropagation.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
